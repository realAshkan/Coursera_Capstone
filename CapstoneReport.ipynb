{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# DATA SCIENCE CAPSTONE PROJECT\n# *Predicting Severity of Collisions*"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### INTRODUCTION: BUSINESS PROBLEM"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As PBS reported in May 2014, The economic and societal harm from motor vehicle crashes amounted to a whopping 871 billion dollars in a single year, according to a study released in 2014 by the National Traffic Safety Administration. The study examined the economic toll of car and truck crashes in 2010, when 32,999 people were killed, 3.9 million injured and 24 million vehicles damaged. Those deaths and injuries were similar to other recent years. Of the total price tag, 277 billion dollars was attributed to economic costs - nearly 900 dollar for every person living in the U.S. that year. Harm from loss of life, pain and decreased quality of life due to injuries was pegged at 594 billion dollars.\n\n\"While the economic and societal costs of crashes are staggering, today\u2019s report clearly demonstrates that investments in safety are worth every penny used to reduce frequency and severity of these tragic events,\u201d Transportation Secretary Anthony Foxx said in a statement in 2014. As the data and statement by the Transportation Secretary suggest, reducing the number and/or severity of car accidents is a major priority for the government, states, and the individuals who get into collisions. \n\nOnce a driver considers the cost of a car accident which could be as significant as losing his/her life, they acknowledge that it would be great if there is something in place that could warn them, given the weather and the road conditions about the possibility of them getting into a car accident and how severe it would be, so that they would drive more carefully or even change their travel if they are able to. As a result, the main users of outputs from a collision severity prediction model are the drivers on the road. In that case, the output can be an additional feature to the navigation system/app and as simple as indicating the liklihood of getting into an accident, potential severity of such accident, and available options for the driver on the road. \n\nThe other benefactors of such prediction model could be the government and the states. One benefit for these agencies could be to evaluate in which areas the road conditions play a more significant role in the occurrence or severity of accidents so they can use their resources more efficiently by improving the infrastructure in more impactful locations. Also, a decrease in the number or severity of accidents would improve the response time to collisions which could save lives in addition to saving a significant amount of money for the states and the government that is spent annually on providing emergency services on the roads."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### DATA"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Several factors affect the occurrence and severity of car accidents. Road, weather, and light conditions are some of the factors that are not under a driver's control but factors such as speed and focus on driving could be easily managed by the drivers to avoid getting into car accidents. In other words, given a certain speed and other factors such as weather and road conditions, we should be able to predict to a certain extent whether an accident might occur and if so, how severe the accident could be. \n\nTo build a model to predict severity of collisions, we will use the collisions database from the State of Seattle that represents all types of collisions from 2004 to 2020 and is provided by SPD and recorded by Traffic Records. Although the results from a model built based on the Seattle collisions database might not be applicable to the other regions are states, this is a major first step to test whether predicting occurrence and severity of car accidents is doable before applying this predictive model to the other states. \n\nThe selected database includes 194,673 observations and 37 attributes, of which, 36 attributes could potentially explain, as independent variables, the severity of accidents, the dependent variable, specified by \"SEVERITYCODE\" in the database. The database provides information for each collision such as location, severity, type, number of people involved, number of vehicles involved, injuries, fatalities, date, lack of attention, driving under influence, weather, road, and light conditions, speeding, and parked car involvement."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### METHODOLOGY"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### *Data Extraction, Transformation, and Loading*\nThe following steps were followed to accomplish the initial step of data analysis towards resolving the business problem:\n- Import libraries and the dataset\n- Conduct initial database loading and exploration\n- Create a subset of original database with features that seem to be relevant to predicting severity of collisions and verify data types\n- Delete unmatched records if they don't constitute a significant portion of the database\n- Delete duplicate dependent variabe, severity code, and transform values for classification\n- Transform time and date attributes to part of a day, weekend/weekday, and season attributes\n- Update and clean dummy variables in the database\n- Evaluate potential impact of selected categorical attributes on severity of collisions before transforming them into dummy variables\n- Evaluate and handle missing values\n  - \"NOT ENOUGH INFORMATION / NOT APPLICABLE\" for SDOT_COLDESC attribute for records with missing JUNCTIONTYPE so those rows is better to be deleted instead of generate the missing values\n  - Delete rows with missing values for important attributes, COLLISIONTYPE and ST_COLCODE\n  - Evaluate the importance of records with missing values for ADDRTYPE, WEATHER, ROADCOND, and LIGHTCOND and delete them if values for severity code (dependent variable) are evently distributed for such records\n  - Distribution of dependent variable for Null ADDRTYPE is very similar to those for Alley. Replacing Null with Alley for the dataset\n  - It seems records with missing values for WEATHER are also missing values for ROADCOND and LIGHTCOND and deleting them could be practical but first further explore those records\n  - The distribution of values for severity code is fairly even for Null values of WEATHER attribute. We can safely delete these records since this is most likely not a systematic signal biased toward a specific outcome\n  - Next, evaluate the distribution of values for severity code for records with Null values for ROADCOND attribute and similarly delete those records if severity code values are evenly distributed\n  - Lastly, evaluate the distribution of values for severity code for records with Null values for LIGHTCOND attribute and similarly delete those records if severity code values are evenly distributed\n\n- Address imbalanced dataset before separating independent variables from the dependent variable by downsampling majority class\n- Separate dependent variable from the independent variables\n  - Create two subsets of independent variables and normalize them\n    - Subset 1 (X1) - All relevant indendent variables\n    - Subset 2 (X2) - Independent variables easily identifiable before a collision\n  - Create a subset for the dependent variable\n\n### *Modeling*\nThe dataset was divided into Training and Test subsets before training standard classification models using the Train subsets:\n- Test/Train partitioning\n  - Partitioning for Subset 1 of independent variables (X1)\n  - Partitioning for Subset 2 of independent variables (X2)\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n### *Model Evaluation using Test set*\nTrained models were evaluated using Test subsets to assess how the developed models perform on predicting out of sample observations:\n- KNN model evaluation for the two separate sets of independent variables\n- Decision Tree model evaluation for the two separate sets of independent variables\n- Support Vector Machine model evaluation for the two separate sets of independent variables\n- Logistic Regression model evaluation for the two separate sets of independent variables"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### RESULTS"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can report the accuracy of the built model using different evaluation metrics."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "- Accuracy of the built model for the first set of independent variables (X1) that include all variables that can potentially determine severity of a collision:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.XX    | 0.XX     | NA      |\n| Decision Tree      | 0.69    | 0.67     | NA      |\n| SVM                | 0.71    | 0.71     | NA      |\n| LogisticRegression | 0.72    | 0.71     | 0.53    |"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "- Accuracy of the built model for the second set of independent variables (X2) that include variables that can potentially determine severity of a collision and are measurable before a collision happens:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.60    | 0.60     | NA      |\n| Decision Tree      | 0.61    | 0.61     | NA      |\n| SVM                | 0.63    | 0.63     | NA      |\n| LogisticRegression | 0.63    | 0.63     | 0.63    |"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### DISCUSSION"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Our models show that predicting severity of accidents using a wide range of measurable variables is possible with a significant level of accuracy. As expected, the first set of variables can predict the severity of an accident with a higher degree of accuracy compared to the second set of variables. The first set include variables such as the codes assigned to the accidents that describe the accidents themselves. Some of the variables in the first set are not measurable before an accident occur and as a result, it is more practical to use the second set of variables to predict severity of collisions. KNN, Decision Tree, SVM, and Logistic Regression predict the severity of accidents with similar levels of accuracy at around 62%. SVM and Logistic Regression models seem to be slightly more accurate than KNN and Decision Tree models.\n\nOur models can predict how severe an accident could be before it happens and warn the driver to take precautions such as slowing down or driving with more attention. This approach could lower or eliminate the possibility of an accident and if an accident happens, it could limit the severity of an accident to property damage instead of human injuriy or death. There are some limitations in this study such as the use of independent variables that may not be identifiable before an accident occur. The data does not incorporate an important factor such as the infrastructure condition or the status of the road/pavement. The dataset only reflects the recorded collisions and it cannot be used to determine probability of getting into an accident since there is no data for no-collision observations. As a result, the model can mainly be used to reduce the severity of a potential accident."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### CONCLUSION"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Car accidents cost billions of dollars every year and reducing the number of collisions and/or decreasing the severity of them would lead to significant cost and human life savings.  There are factors that can potentially affect occurrence and/or severity of accidents and these factors are mostly measurable prior to an accident. We believe that using these variables, we should be able to inform a driver the possibility and severity of a potential accident which would work as a warning to the driver to adjust his/her driving.\n\nOur models show that predicting severity of accidents is possible to a reasonable level using a wide range of measurable variables. Our model can predict how severe an accident could be before it happens and warn the driver to take precautions such as slowing down or driving with more attention. This approach could lower or eliminate the possibility of an accident and if an accident happens, it could limit the severity of an accident to property damage instead of human injuriy or death. \n\nThe next step could be to capture more data for the State of Seattle collisions such as pavement condition and also add other driving violations such as speeding that could be used as a proxy for careless driving behavior that has not led to collisions. Next, we should test the output and recommendation made by the model on the road to see whether it would lead to a significant decrease in severity of accidents in Seattle. If the test is successful, we will apply the approach used in this project to other states."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}